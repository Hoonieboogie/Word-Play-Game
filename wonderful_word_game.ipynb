{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ab8e712",
   "metadata": {},
   "source": [
    "# 유사한 단어 찾기 게임\n",
    "(임베딩 모델 학습 부분까지는 건너뛰고 그 다음부터 실행해야 합니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdcb966",
   "metadata": {},
   "source": [
    "1. 사전 학습된 모델 또는 적절한 데이터뎃을 찾는다\n",
    "2. 워드 임베딩 모델을 학습시킨다\n",
    "3. 단어 유사도가 0.8인 A,B를 랜덤 추출한다\n",
    "4. A,B와 대응되는 C를 추출한다\n",
    "5. D를 입력받는다\n",
    "\n",
    "=> A:B = C:D 관계에 대응하는 D를 찾는 게임을 만든다.\n",
    "ex) A:산, B:바다, C:나무, D:물"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e3ae6",
   "metadata": {},
   "source": [
    "**<출력 예시>**\n",
    "\n",
    "관계) [ 수긍 : 추락 = 대사관 : ?] <br>\n",
    "모델이 예측한 가장 적합한 단어: 잠입 <br>\n",
    "당신의 답변과 모델 예측의 유사도: 0.34 <br>\n",
    "아쉽네요. 더 생각해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d240d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7ac21",
   "metadata": {},
   "source": [
    "- 데이터 출처: https://github.com/kakaobrain/kor-nlu-datasets/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071038c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                개념적으로 크림 스키밍은 제품과 지리라는 두 가지 기본 차원을 가지고 있다.\n",
       "1         시즌 중에 알고 있는 거 알아? 네 레벨에서 다음 레벨로 잃어버리는 거야 브레이브스...\n",
       "2                         우리 번호 중 하나가 당신의 지시를 세밀하게 수행할 것이다.\n",
       "3                              어떻게 아세요? 이 모든 것이 다시 그들의 정보다.\n",
       "4         그래, 만약 네가 테니스화 몇 개를 사러 간다면, 나는 왜 그들이 100달러대에서 ...\n",
       "                                ...                        \n",
       "762701                                    캘리포니아는 더 잘할 수 없다.\n",
       "762702                         그래서 원래의 많은 건물들이 편의점으로 대체되었다.\n",
       "762703                 하우스보트의 전통은 영국 라지가 여전히 강해지는 동안 시작되었다.\n",
       "762704                부고문은 아름다웠고 연예계에서의 그의 업적에 대해 현물로 쓰여졌다.\n",
       "762705          남편이 요즘 너무 과로해서 이 근처에서 많은 일을 부탁할 용기가 나지 않는다.\n",
       "Length: 762706, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'word_game_data.tsv',\n",
    "    sep='\\t',\n",
    "    engine='python',        # 파이썬 엔진이 불량 행에 관대\n",
    "    on_bad_lines='skip',    # 문제 있는 줄은 건너뜀 ('warn'으로 바꾸면 경고만)\n",
    "    dtype=str               # 타입 추정으로 인한 추가 오류 방지\n",
    ")\n",
    "\n",
    "ser1 = df['sentence1']\n",
    "ser2 = df['sentence2']\n",
    "\n",
    "combined_ser = pd.concat([ser1, ser2], axis=0).reset_index(drop=True)\n",
    "combined_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6841ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "combined_ser.isna().sum()\n",
    "\n",
    "# 결측치 처리\n",
    "combined_ser = combined_ser.dropna(how='any')\n",
    "combined_ser.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc85765",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f28975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762666/762666 [42:53<00:00, 296.31it/s]  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "# 영문자 포함 여부 (영어가 1글자라도 섞이면 제거)\n",
    "HAS_LATIN = re.compile(r'[A-Za-z]')\n",
    "\n",
    "# 의미 희석 토큰(명사에도 많이 섞여 나오는 것들)\n",
    "EXTRA_STOPS = {\n",
    "    \"적\",\"라는\",\"만큼\",\"대로\",\"듯\",\"듯이\",\"거\",\"것\",\"수\",\"등\",\"중\",\n",
    "    \"가지\",\"두\",\"다음\",\"및\",\"그러나\",\"하지만\",\"또\",\"또한\",\"그리고\",\n",
    "    \"있다\",\"하다\",\"되다\"  \n",
    "}\n",
    "\n",
    "def tokenize_clean_nouns(sent):\n",
    "    if not isinstance(sent, str) or not sent.strip():\n",
    "        return []\n",
    "    # 공백 정리\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    # 품사 태깅 (정규화 + 원형복원)\n",
    "    pos = okt.pos(sent, norm=True, stem=True)\n",
    "    out = []\n",
    "    for tok, tag in pos:\n",
    "        # 1) 명사만 남김\n",
    "        if tag != \"Noun\":\n",
    "            continue\n",
    "        # 2) 영어 포함 토큰 제거\n",
    "        if HAS_LATIN.search(tok):\n",
    "            continue\n",
    "        # 3) 추가 불용어 제거\n",
    "        if tok in EXTRA_STOPS:\n",
    "            continue\n",
    "        # 4) 한 글자 토큰 제거(원하면 조건 완화 가능)\n",
    "        if len(tok) <= 1:\n",
    "            continue\n",
    "        out.append(tok)\n",
    "    return out\n",
    "\n",
    "preprocessed_data = [tokenize_clean_nouns(s) for s in tqdm(combined_ser)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9e114c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['걱정']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data[2700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f60d6a",
   "metadata": {},
   "source": [
    "임베딩 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e229fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "embedding_model = FastText(\n",
    "    sentences=preprocessed_data,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=0\n",
    ")\n",
    "\n",
    "embedding_model.wv.vectors.shape\n",
    "embedding_model.wv.save_word2vec_format('word_game_w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5aa748",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98226e71",
   "metadata": {},
   "source": [
    "## 여기서부터 실행하면 됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9254ff4",
   "metadata": {},
   "source": [
    "저장된 모델 로드해서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea2146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 로드\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "load_model = KeyedVectors.load_word2vec_format('word_game_w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80d5ed",
   "metadata": {},
   "source": [
    "게임 실행 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7fa60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def game_start(model):\n",
    "    \n",
    "    def random_similar_pair(model, max_attempts=500):\n",
    "        \"\"\"\n",
    "        반환: (word_a, word_b, 유사도)\n",
    "        \"\"\"\n",
    "        words = list(model.index_to_key)\n",
    "        for _ in range(max_attempts):\n",
    "            w1 = random.choice(words)\n",
    "            sims = model.most_similar(w1) \n",
    "            cands = [(w2, s) for w2, s in sims if s >= 0.8]\n",
    "            if cands:\n",
    "                w2, s = random.choice(cands)\n",
    "                return w1, w2, float(s)\n",
    "        raise RuntimeError(f\"No pair found with similarity >= 0.8 after {max_attempts} attempts.\")\n",
    "    \n",
    "    word_A, word_B, sim_score = random_similar_pair(load_model, max_attempts=1000) # A,B 랜덤추출\n",
    "    word_C, C_sim_score = model.most_similar(negative=[word_A], topn=1)[0] # 대응되는 C 추출 (기준: 대척점)\n",
    "    model_word = model.most_similar(word_C)[0][0] # 모델이 예측한 가장 적합한 단어\n",
    "\n",
    "\n",
    "    # 플레이\n",
    "    print(f\"관계) {word_A}:{word_B} = {word_C}:?\")\n",
    "    try:\n",
    "        word_D = input(\"단어를 입력하세요: \")\n",
    "        similarity_score = model.similarity(word_C, word_D)\n",
    "        print(f\"모델이 예측한 가장 적합한 단어: {model_word}\")\n",
    "        print(f\"당신의 답변과 모델 예측의 유사도: {similarity_score}\")\n",
    "        if similarity_score > 0.8:\n",
    "            print(\"훌륭합니다.\")\n",
    "        else:\n",
    "            print(\"아쉽네요 더 생각해보세요\")\n",
    "    except KeyError: \n",
    "        print(\"없는 단어입니다. 다시 시작하세요.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e052db",
   "metadata": {},
   "source": [
    "# 게임 실행!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1570f2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관계) 전시회:전시품 = 상대방:?\n",
      "모델이 예측한 가장 적합한 단어: 상대성\n",
      "당신의 답변과 모델 예측의 유사도: 0.7213615775108337\n",
      "아쉽네요 더 생각해보세요\n"
     ]
    }
   ],
   "source": [
    "## 실행하면 게임이 시작됩니다!\n",
    "game_start(load_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
